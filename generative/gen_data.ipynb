{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534f7976",
   "metadata": {},
   "source": [
    "# Gen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8504a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ESCAPE_MAP_DRAFT\\PGM\\source\\numba_utilities.py:1124: NumbaPerformanceWarning: \u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (Array(float32, 2, 'F', False, aligned=True), Array(float32, 2, 'A', False, aligned=True))\u001b[0m\u001b[0m\n",
      "  dmean_v_dw = np.dot(s1.T, V)\n",
      "E:\\ESCAPE_MAP_DRAFT\\PGM\\source\\numba_utilities.py:961: NumbaPerformanceWarning: \u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (Array(float32, 1, 'A', False, aligned=True), Array(float32, 2, 'A', False, aligned=True))\u001b[0m\u001b[0m\n",
      "  mean_V = np.dot(weights, V) / sum_weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29 KD vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Roaming\\Python\\Python312\\site-packages\\Bio\\pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from global_variables import *\n",
    "from escape_map import EscapeMap, load_escape_map_from_csv,gen_artif_data, score_seq_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31481e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import utils from ../rbm\n",
    "pgm_dir=('../')\n",
    "sys.path.append(pgm_dir+'./utilities')\n",
    "\n",
    "# Now safe to import\n",
    "import utilities, Proteins_utils, sequence_logo, plots_utils\n",
    "import rbm, RBM_utils  # rbm.py must be alongside this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49e795e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (100, 178)\n",
      "Generating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (100, 178)\n",
      "Generating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (100, 178)\n",
      "Generating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:26<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (100, 178)\n",
      "Generating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:28<00:00,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (100, 178)\n",
      "All sequences saved to 'generated_sequences_beta.fasta'\n",
      "Scores saved to 'generated_sequences_scores_beta.csv'\n",
      "Total sequences: 500\n",
      "  seq_id      score  coeff_beta\n",
      "0   seq0  57.397344         0.5\n",
      "1   seq1  57.756809         0.5\n",
      "2   seq2  57.669490         0.5\n",
      "3   seq3  57.567324         0.5\n",
      "4   seq4  57.736968         0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Reproducibility (optional) ---\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Load model and set base concentrations ---\n",
    "model = load_escape_map_from_csv(\"../fitness/params_sigmoid_diff.csv\")\n",
    "model.raw_concentrations = -12.0 * np.ones(len(KD_VECTORS), dtype=np.float64)\n",
    "\n",
    "# total_beta = (1 / exp(raw_beta)) * coeff_beta\n",
    "base_beta_factor = 1.0 / np.exp(model.raw_beta)\n",
    "\n",
    "# --- Beta sweep & sampling config ---\n",
    "BETA_LIST = [0.5, 0.8, 1,2,3]\n",
    "N_SEQUENCES_PER_BETA = 100\n",
    "N_CHAINS = 5\n",
    "WARMING_STEPS = 1000\n",
    "STEPS_BETWEEN = 100\n",
    "\n",
    "# --- Outputs we’ll accumulate across betas ---\n",
    "fasta_lines = []\n",
    "score_rows = []\n",
    "seq_counter = 0\n",
    "\n",
    "for coeff_beta in BETA_LIST:\n",
    "    # set current beta (no copying needed; just update the scalar)\n",
    "    model.total_beta = base_beta_factor * float(coeff_beta)\n",
    "\n",
    "    # --- Generate sequences ---\n",
    "    seqs = gen_artif_data(\n",
    "        model,\n",
    "        n_sequences=N_SEQUENCES_PER_BETA,\n",
    "        n_chains=N_CHAINS,\n",
    "        warming_steps=WARMING_STEPS,\n",
    "        steps_between_sampling=STEPS_BETWEEN,\n",
    "        # init_seq=INIT_SEQ,  # optional\n",
    "    )\n",
    "\n",
    "    # --- Score sequences (normalize like your original script) ---\n",
    "    scores = score_seq_batch(model, seqs) / model.total_beta  # (N,)\n",
    "\n",
    "    # --- Convert to amino-acid strings and append to global FASTA ---\n",
    "    seqs_str = Proteins_utils.num2seq(seqs)\n",
    "    for seq_str, sc in zip(seqs_str, scores):\n",
    "        seq_id = f\"seq{seq_counter}\"\n",
    "        fasta_lines.append(f\">{seq_id} | beta={coeff_beta:.3f}\\n{seq_str}\\n\")\n",
    "        score_rows.append({\n",
    "            \"seq_id\": seq_id,\n",
    "            \"score\": float(sc),\n",
    "            \"coeff_beta\": float(coeff_beta),\n",
    "        })\n",
    "        seq_counter += 1\n",
    "\n",
    "# --- Save a single FASTA with all sequences across betas ---\n",
    "with open(\"generated_sequences_beta.fasta\", \"w\") as fasta_file:\n",
    "    fasta_file.writelines(fasta_lines)\n",
    "print(\"All sequences saved to 'generated_sequences_beta.fasta'\")\n",
    "\n",
    "# --- Save one CSV with seq_id, score, coeff_beta ---\n",
    "scores_df = pd.DataFrame(score_rows, columns=[\"seq_id\", \"score\", \"coeff_beta\"])\n",
    "scores_df.to_csv(\"generated_sequences_scores_beta.csv\", index=False)\n",
    "print(\"Scores saved to 'generated_sequences_scores_beta.csv'\")\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Total sequences:\", len(scores_df))\n",
    "print(scores_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cdcbf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefixed 500 sequences.\n",
      "Wrote: generated_sequences_beta_prefixed.fasta\n",
      "Example:\n",
      ">seq0 | beta=0.500\n",
      "TNLCPFGEVFNATRFASVYQWNRQRVSNCVADYSVLYNSVFFSTFKCYGVSNTKLNDLCFLSVYADSFVIPGDEVRQIAP...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "INPUT_FASTA  = \"generated_sequences_beta.fasta\"       # or \"generated_sequences_beta.fasta\"\n",
    "OUTPUT_FASTA = \"generated_sequences_beta_prefixed.fasta\"\n",
    "PREFIX = \"TNLCPFGEVFNATRFA\"\n",
    "\n",
    "def read_fasta(path):\n",
    "    records = []\n",
    "    header, seq_chunks = None, []\n",
    "    with open(path, \"r\") as fh:\n",
    "        for line in fh:\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\">\"):\n",
    "                if header is not None:\n",
    "                    records.append((header, \"\".join(seq_chunks)))\n",
    "                header, seq_chunks = line, []\n",
    "            else:\n",
    "                seq_chunks.append(line.strip())\n",
    "        if header is not None:\n",
    "            records.append((header, \"\".join(seq_chunks)))\n",
    "    return records\n",
    "\n",
    "def write_fasta(records, path, wrap_width=None):\n",
    "    with open(path, \"w\") as fh:\n",
    "        for header, seq in records:\n",
    "            fh.write(f\"{header}\\n\")\n",
    "            if wrap_width and wrap_width > 0:\n",
    "                for i in range(0, len(seq), wrap_width):\n",
    "                    fh.write(seq[i:i+wrap_width] + \"\\n\")\n",
    "            else:\n",
    "                fh.write(seq + \"\\n\")\n",
    "\n",
    "# Read, prepend, write\n",
    "records = read_fasta(INPUT_FASTA)\n",
    "prefixed = [(h, PREFIX + s) for (h, s) in records]\n",
    "write_fasta(prefixed, OUTPUT_FASTA, wrap_width=0)  # set to 80 if you want wrapped lines\n",
    "\n",
    "print(f\"Prefixed {len(prefixed)} sequences.\")\n",
    "print(f\"Wrote: {OUTPUT_FASTA}\")\n",
    "# quick peek\n",
    "if prefixed:\n",
    "    print(\"Example:\")\n",
    "    print(prefixed[0][0])\n",
    "    print(prefixed[0][1][:80] + (\"...\" if len(prefixed[0][1])>80 else \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19319927",
   "metadata": {},
   "source": [
    "# Beta=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6bcc32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:43<00:00, 40.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (1000, 178)\n",
      "All sequences saved to 'generated_sequences_beta3.fasta'\n",
      "Scores saved to 'generated_sequences_scores_beta3.csv'\n",
      "Total sequences: 1000\n",
      "  seq_id      score  coeff_beta\n",
      "0   seq0  61.636061         3.0\n",
      "1   seq1  61.646540         3.0\n",
      "2   seq2  61.879691         3.0\n",
      "3   seq3  61.879691         3.0\n",
      "4   seq4  61.858077         3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Reproducibility (optional) ---\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Load model and set base concentrations ---\n",
    "model = load_escape_map_from_csv(\"../fitness/params_sigmoid_diff.csv\")\n",
    "model.raw_concentrations = -12.0 * np.ones(len(KD_VECTORS), dtype=np.float64)\n",
    "\n",
    "# total_beta = (1 / exp(raw_beta)) * coeff_beta\n",
    "base_beta_factor = 1.0 / np.exp(model.raw_beta)\n",
    "\n",
    "# --- Beta sweep & sampling config ---\n",
    "BETA_LIST = [3]\n",
    "N_SEQUENCES_PER_BETA = 1000\n",
    "N_CHAINS = 10\n",
    "WARMING_STEPS = 1000\n",
    "STEPS_BETWEEN = 100\n",
    "\n",
    "# --- Outputs we’ll accumulate across betas ---\n",
    "fasta_lines = []\n",
    "score_rows = []\n",
    "seq_counter = 0\n",
    "\n",
    "for coeff_beta in BETA_LIST:\n",
    "    # set current beta (no copying needed; just update the scalar)\n",
    "    model.total_beta = base_beta_factor * float(coeff_beta)\n",
    "\n",
    "    # --- Generate sequences ---\n",
    "    seqs = gen_artif_data(\n",
    "        model,\n",
    "        n_sequences=N_SEQUENCES_PER_BETA,\n",
    "        n_chains=N_CHAINS,\n",
    "        warming_steps=WARMING_STEPS,\n",
    "        steps_between_sampling=STEPS_BETWEEN,\n",
    "        # init_seq=INIT_SEQ,  # optional\n",
    "    )\n",
    "\n",
    "    # --- Score sequences (normalize like your original script) ---\n",
    "    scores = score_seq_batch(model, seqs) / model.total_beta  # (N,)\n",
    "\n",
    "    # --- Convert to amino-acid strings and append to global FASTA ---\n",
    "    seqs_str = Proteins_utils.num2seq(seqs)\n",
    "    for seq_str, sc in zip(seqs_str, scores):\n",
    "        seq_id = f\"seq{seq_counter}\"\n",
    "        fasta_lines.append(f\">{seq_id} | beta={coeff_beta:.3f}\\n{seq_str}\\n\")\n",
    "        score_rows.append({\n",
    "            \"seq_id\": seq_id,\n",
    "            \"score\": float(sc),\n",
    "            \"coeff_beta\": float(coeff_beta),\n",
    "        })\n",
    "        seq_counter += 1\n",
    "\n",
    "# --- Save a single FASTA with all sequences across betas ---\n",
    "with open(\"generated_sequences_beta3.fasta\", \"w\") as fasta_file:\n",
    "    fasta_file.writelines(fasta_lines)\n",
    "print(\"All sequences saved to 'generated_sequences_beta3.fasta'\")\n",
    "\n",
    "# --- Save one CSV with seq_id, score, coeff_beta ---\n",
    "scores_df = pd.DataFrame(score_rows, columns=[\"seq_id\", \"score\", \"coeff_beta\"])\n",
    "scores_df.to_csv(\"generated_sequences_scores_beta3.csv\", index=False)\n",
    "print(\"Scores saved to 'generated_sequences_scores_beta3.csv'\")\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Total sequences:\", len(scores_df))\n",
    "print(scores_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
