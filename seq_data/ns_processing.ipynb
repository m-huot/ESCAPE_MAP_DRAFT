{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368525ad",
   "metadata": {},
   "source": [
    "# Nexstrain Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf565130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 99773 sequences to E:\\ESCAPE_MAP_DRAFT\\seq_data\\ns_mutated_spike.fasta\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# ----- constants -----\n",
    "IN_PATH = Path(\"ns_metadata_100k.tsv\")   # adjust if needed\n",
    "OUT_PATH = Path(\"ns_mutated_spike_100k.fasta\")\n",
    "\n",
    "# User-provided WT Spike segment\n",
    "WT = \"SVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCG\"\n",
    "\n",
    "# Positions covered by WT in Wuhan-Hu-1 Spike numbering\n",
    "ABS_START = 349\n",
    "ABS_END = 348 + len(WT)  # inclusive\n",
    "\n",
    "# ----- helper functions -----\n",
    "def get_sequence(WT_seq: str, site_abs: int, mutation_to: str, wt_aa: str) -> str:\n",
    "    \"\"\"Apply single substitution after checking WT residue.\"\"\"\n",
    "    site = site_abs - ABS_START\n",
    "    if mutation_to=='*':\n",
    "        return WT_seq\n",
    "    assert WT_seq[site] == wt_aa, f\"WT residue mismatch at {site_abs}: found {WT_seq[site]}, expected {wt_aa}\"\n",
    "    return WT_seq[:site] + mutation_to + WT_seq[site + 1:]\n",
    "\n",
    "# Parse tokens like \"S:R158G\" and return (from_aa, pos_abs, to_aa) or None\n",
    "_mut_re = re.compile(r\"^S:([A-Z\\*])(\\d+)([A-Z\\*])$\")\n",
    "\n",
    "def parse_spike_sub(token: str):\n",
    "    token = token.strip()\n",
    "    m = _mut_re.match(token)\n",
    "    if not m:\n",
    "        return None\n",
    "    f, pos, t = m.group(1), int(m.group(2)), m.group(3)\n",
    "    return f, pos, t\n",
    "\n",
    "def apply_spike_mutations(WT_seq: str, aa_substitutions: str) -> tuple[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Keep S: substitutions whose absolute site lies in [ABS_START, ABS_END].\n",
    "    Apply only if current residue matches the 'from' amino acid.\n",
    "    \"\"\"\n",
    "    if not isinstance(aa_substitutions, str) or not aa_substitutions.strip():\n",
    "        return WT_seq, []\n",
    "\n",
    "    tokens = [t.strip() for t in re.split(r\"[,\\s]+\", aa_substitutions) if t.strip()]\n",
    "    applied = []\n",
    "    seq = WT_seq\n",
    "\n",
    "    for tok in tokens:\n",
    "        if not tok.startswith(\"S:\"):\n",
    "            continue\n",
    "        parsed = parse_spike_sub(tok)\n",
    "        if not parsed:\n",
    "            continue\n",
    "        from_aa, pos_abs, to_aa = parsed\n",
    "\n",
    "        # within window\n",
    "        if pos_abs < ABS_START or pos_abs > ABS_END:\n",
    "            continue\n",
    "\n",
    "        idx = pos_abs - ABS_START\n",
    "        if idx < 0 or idx >= len(seq):\n",
    "            continue\n",
    "\n",
    "        # compatible?\n",
    "        if seq[idx] != from_aa:\n",
    "            continue\n",
    "\n",
    "        # apply with WT check\n",
    "        seq = get_sequence(seq, pos_abs, to_aa, from_aa)\n",
    "        applied.append(tok)\n",
    "\n",
    "    return seq, applied\n",
    "\n",
    "def fasta_header(date, region, lineage):\n",
    "    d = \"\" if pd.isna(date) else str(date)\n",
    "    r = \"\" if pd.isna(region) else str(region)\n",
    "    p = \"\" if pd.isna(lineage) else str(lineage)\n",
    "    return f\">{d}|{r}|{p}\"\n",
    "\n",
    "# ----- main -----\n",
    "def main():\n",
    "    df = pd.read_csv(IN_PATH, sep=\"\\t\", dtype=str, keep_default_na=True, na_values=[\"\", \"NA\", \"NaN\"])\n",
    "\n",
    "    required = [\"date\", \"region\", \"pango_lineage\", \"aaSubstitutions\"]\n",
    "    for col in required:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    out_lines = []\n",
    "    for _, row in df.iterrows():\n",
    "        date = row[\"date\"]\n",
    "        region = row[\"region\"]\n",
    "        lineage = row[\"pango_lineage\"]\n",
    "        aa_subs = row[\"aaSubstitutions\"]\n",
    "\n",
    "        mutated_seq, _ = apply_spike_mutations(WT, aa_subs)\n",
    "\n",
    "        header = fasta_header(date, region, lineage)\n",
    "        out_lines.append(header)\n",
    "        out_lines.append(mutated_seq)\n",
    "\n",
    "    OUT_PATH.write_text(\"\\n\".join(out_lines) + \"\\n\", encoding=\"utf-8\")\n",
    "    print(f\"Wrote {len(out_lines)//2} sequences to {OUT_PATH.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
